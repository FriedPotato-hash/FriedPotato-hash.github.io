
---
title:  "BoxDiff"
excerpt: "md íŒŒì¼ì— ë§ˆí¬ë‹¤ìš´ ë¬¸ë²•ìœ¼ë¡œ ì‘ì„±í•˜ì—¬ Github ì›ê²© ì €ì¥ì†Œì— ì—…ë¡œë“œ í•´ë³´ì. ì—ë””í„°ëŠ” Visual Studio code ì‚¬ìš©! ë¡œì»¬ ì„œë²„ì—ì„œ í™•ì¸ë„ í•´ë³´ì. "

categories:
  - Paper/{Editing}
tags:
  - 

toc: true
toc_sticky: true

---

## Intro
- â€œtraining-free mannerâ€
- â€œsimplest form of user-provided conditionsâ€
- â€œcontrol the location and scaleâ€
- â€œpre-trained text-to-image diffusion modelâ€
- â€œfinetuning time are required for nurturing models.â€ 

- As you know, recent T2I diffusion models have capacity to generate high-quality images corresponding to user given prompts, which have limitation for assigning scale or location of desired images. To alleviate this limitation, researchers have suggested some lines of studies.  
  
- One line of study is to finetuning some appending layers for adopting diffusion model for some spatial conditions(bbox, keypoints, etc). But this kinds of methods require fine-tuningÂ  the diffusion model, not surprisingly, this process can be a huge bottleneck for uses who don't have large computing power.  
  
- So, this paper suggest `training-free` method for controling the lcoatino and scale of contents in the image synthesized by pre-trained T2I diffusion models.

- Layout-to-image literature, whose setting is restricted to the limited closed-set categories. And most of them followed the fully-supervised learning pipeline, requiring huge paired condition-image data.
## Method
- This represents the cross-attention maps between target text tokens and intermediate features of Unet(SD).  
- Specific spatial attention maps for objects or contexts in text prompt can be extracted.  So, the idea is quite simple, we can contol the spatial location and scale of objects/contexts to be synthesized by adding guidance or constraints on the extracted cross-attentions.  
- The methods dubbed, Box-Constrained Diffusion, to add three spatial constraints (Inner-Box, Outer-Box, and Corner Constraints) on the cross attention extracted at each denoising time steps.
- â€œThis plays a role in pointing out directions to update the noised latent vector, which consequently leads synthesized objects or contexts to gradually follow the given spatial conditions.â€
![[Pasted image 20230913232039.png]]
- Overall Method![[Pasted image 20230913232117.png]]
## Experiment
- Ablation
  T2I-Sim: Text-to-Image Similarity
  ![[ìŠ¤í¬ë¦°ìƒ· 2023-09-13 ì˜¤í›„ 11.21.49.png|500]]
- Qual Results ![[ìŠ¤í¬ë¦°ìƒ· 2023-09-13 ì˜¤í›„ 11.21.38.png]]
## Conclusion from ğŸ¦–
- Self Attention layer and Cross attention layer which laid in SD Unet architecture play significantly import role. Especially, the location, scale (etc), I mean, most of the spatial condition of generated images depends heavily on Attention Layers.
- I think the self-attention control mechanism have the same mechanism with the Shape-guided diffusion control.