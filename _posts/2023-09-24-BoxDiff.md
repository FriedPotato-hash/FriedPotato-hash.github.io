
---
title:  "BoxDiff"
excerpt: "md 파일에 마크다운 문법으로 작성하여 Github 원격 저장소에 업로드 해보자. 에디터는 Visual Studio code 사용! 로컬 서버에서 확인도 해보자. "

categories:
  - Paper/{Editing}
tags:
  - 

toc: true
toc_sticky: true

---

## Intro
- “training-free manner”
- “simplest form of user-provided conditions”
- “control the location and scale”
- “pre-trained text-to-image diffusion model”
- “finetuning time are required for nurturing models.” 

- As you know, recent T2I diffusion models have capacity to generate high-quality images corresponding to user given prompts, which have limitation for assigning scale or location of desired images. To alleviate this limitation, researchers have suggested some lines of studies.  
  
- One line of study is to finetuning some appending layers for adopting diffusion model for some spatial conditions(bbox, keypoints, etc). But this kinds of methods require fine-tuning  the diffusion model, not surprisingly, this process can be a huge bottleneck for uses who don't have large computing power.  
  
- So, this paper suggest `training-free` method for controling the lcoatino and scale of contents in the image synthesized by pre-trained T2I diffusion models.

- Layout-to-image literature, whose setting is restricted to the limited closed-set categories. And most of them followed the fully-supervised learning pipeline, requiring huge paired condition-image data.
## Method
- This represents the cross-attention maps between target text tokens and intermediate features of Unet(SD).  
- Specific spatial attention maps for objects or contexts in text prompt can be extracted.  So, the idea is quite simple, we can contol the spatial location and scale of objects/contexts to be synthesized by adding guidance or constraints on the extracted cross-attentions.  
- The methods dubbed, Box-Constrained Diffusion, to add three spatial constraints (Inner-Box, Outer-Box, and Corner Constraints) on the cross attention extracted at each denoising time steps.
- “This plays a role in pointing out directions to update the noised latent vector, which consequently leads synthesized objects or contexts to gradually follow the given spatial conditions.”
![[Pasted image 20230913232039.png]]
- Overall Method![[Pasted image 20230913232117.png]]
## Experiment
- Ablation
  T2I-Sim: Text-to-Image Similarity
  ![[스크린샷 2023-09-13 오후 11.21.49.png|500]]
- Qual Results ![[스크린샷 2023-09-13 오후 11.21.38.png]]
## Conclusion from 🦖
- Self Attention layer and Cross attention layer which laid in SD Unet architecture play significantly import role. Especially, the location, scale (etc), I mean, most of the spatial condition of generated images depends heavily on Attention Layers.
- I think the self-attention control mechanism have the same mechanism with the Shape-guided diffusion control.