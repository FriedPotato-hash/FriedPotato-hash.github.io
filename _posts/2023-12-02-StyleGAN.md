A Style-Based Generator Architecture for Generative Adversarial Networks

### Abstract

<aside> ⛰️ 기존의 PGGAN에다가 generator 구조를 재구성 (style transfer 개념을 적용하였음.)하여 생성되는 이미지에 대한 style을 scale-specific하게 조정할 수 있게 되었다.

</aside>

alternative generator architecture for GAN, borrowing from style transfer literature, which leads to an unsupervised separation of high-level attributes(pose, identity) and stochastic variation (주근깨, 머리카락)

This enables intuitive, scale-specific control of synthesis.

⇒ Better interpolation properties, and also better disentangles the latent factors of variation.

---

### Introduction

`**기존 방법들의 문제점**`

GAN모델이 Blackbox라는 점.

The understanding of various aspects of the image synthesis process is still leaking.

The properties of the latent space are also poorly understood, and the commonly demonstrated latent space interpolations [12, 48, 34] provide no quantitative way to compare different generators against each other.

**`모델의 장점 및 특징 소개`**

We do not modify the discriminator or the loss function in any way.

The input latent space must follow the probability density of the training data, and we argue that this leads to some degree of unavoidable entanglement. Our intermediate latent space is free from that restriction and is therefore allowed to be disentangled.

latent space의 disentanglement를 측정하는 이전의 방법들은 해당 연구에서 사용하기에 적합하지 않은 면이 있어서, 두개의 metrics를 새롭게 제안함 ⇒ perceptual path length, linear separability.

⇒ generator가 각각의 factor variation에 따라 선형적으로, less entangled한 representation을 뽑아낸다는 것을 증명한다.

<aside> ⛰️ 찾아볼 질문 _**Q. perceptual path length, linear separability A. 하단 참조**_

_**Q. style-transfer 계열을 적용했다는데 어떻게? A. style을 y_s, y_b로 구분해서 adjacent features (남자&턱수염)을 disentanglement할 수 있도록 만들어 줌.**_

</aside>

---

## Method
![](../source/Pasted%20image%2020231202002654.png)
- W가 AdaIN을 통해 style을 입힐 때 shape이 안맞아 Affine Transformation을 거쳐서 shape을 맞춰줍니다.
    
- layer를 거치면 학습이 불안정해져서 normalization을 각 layer에다 추가하는 StyleGAN에서는 그 역할을 AdaIN이 합니다.
    
- style을 입히는 개념은 _y_{s_,*i}*곱하고 _y_{b_,*i}*를 더하는 과정입니다.
    
    (각각 scale, bias라고 생각해주면 됨.)
    
![](../source/Pasted%20image%2020231202002642.png)
- AdaIN에서 정규화를 할 때 마다 한번에 하나씩만 W가 기여하므로 하나의 style이 각각의 scale에서만 영향을 끼칠 수있도록 분리를 해주는 효과를 갖습니다. 따라서 본 논문 저자들은 style을 분리하는 방법으로 AdaIN이 효과적이라고 말을 하고 있습니다.
![](../source/Pasted%20image%2020231202002636.png)