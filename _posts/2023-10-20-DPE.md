
---
title:  "DPE: Disentanglement of Pose and Expression for General Video Portrait Editing"

categories:
  - Paper/Talking_head
tags:
  - [stable_diffusion, talking_head]

toc: true
toc_sticky: true
 
date: 2023-10-20 
last_modified_at: 2023-10-20

---
#CVPR23 

## Intro
- Head pose and facial expression are always entangled in facial motion and transferred simultaneously. However, the entanglement sets up a barrier for these methods to be used in video portrait editing directly, where it may require to modify the expression only while maintaining the pose unchanged. One challenge of decoupling pose and expression is the lack of paired data, such as the same pose but different expressions. Only a few methods attempt to tackle this challenge with the feat of 3D Morphable Models (3DMMs) for explicit disentanglement. But 3DMMs are not accurate enough to capture facial details due to the limited number of Blendshapes, which has side effects on motion transfer. In this paper, we introduce a novel self-supervised disentanglement framework to decouple pose and expression without 3DMMs and paired data, which consists of a motion editing module, a pose generator, and an expression generator. The editing module projects faces into a latent space where pose motion and expression motion can be disentangled, and the pose or expression transfer can be performed in the latent space conveniently via addition. The two generators render the modified latent codes to images, respectively. Moreover, to guarantee the disentanglement, we propose a bidirectional cyclic training strategy with well-designed constraints.
- Top: disentanglement of pose and expression. Bottom: general video editing. Our method can edit the pose or expression of the source image independently according to the driving image through decoupling pose and expression in motion transfer. Benefiting from the disentanglement, our one-shot talking face method can be applied to video portrait editing. Since our method can edit expression only, the edited cropped face can be pasted back to the full image simply. As our method is subject-agnostic, it can be used to edit any unseen video as well, which is different from subject-dependent video editing methods such as DVP [18].![](../source/Pasted%20image%2020231020203355.png)

## Method
- The framework consists of three learnable components, i.e., the motion editing module, the expression generator, and the pose generator. The editing module projects the source and driving images into a latent space where pose motion and expression motion can be disentangled, and then modifies the latent code of the source image according to a given indicator that points out either expression or pose to edit. It outputs an edited latent code and the feature maps of the source image. The pose and expression generators are applied to render the outputs of the editing module to a face image. These two generators share the same architecture but different parameters for interpreting the pose and expression code respectively.![|500](../source/Pasted%20image%2020231020203528.png)![|500](../source/Pasted%20image%2020231020203624.png)

## Experiment
- ![](../source/Pasted%20image%2020231020203810.png)
- ![](../source/Pasted%20image%2020231020203849.png)
- ![](../source/Pasted%20image%2020231020203719.png)
- ![](../source/Pasted%20image%2020231020203745.png)
- ![](../source/Pasted%20image%2020231020203911.png)
- ![](../source/Pasted%20image%2020231020203927.png)
## Conclusion from ðŸ¦–
- I thought that disentanglement of pose & expression 