
---
title:  "Palette: Image-to-Image Diffusion Models"
 
date: 2023-11-24 
last_modified_at: 2023-11-24

---
### Abstract

<aside> â›°ï¸ 1. specific customizationì´ í•„ìš”ì—†ëŠ” generalí•œ I2I model, Pallete ì œì•ˆ 2. L1/L2 lossê°€ denoising lossì— ì ìš©ë  ë•Œ ë¶„ì„ 3. self-attention Layerì˜ ì¤‘ìš”ì„±ì„ ì‹¤í—˜ìœ¼ë¡œ ì¦ëª… 4. ImageNet ê¸°ë°˜ìœ¼ë¡œ ìƒˆë¡œìš´ evaluation metric ì œì•ˆ

</aside>
![](../source/ìŠ¤í¬ë¦°ìƒ·%202023-11-24%20ì˜¤í›„%209.05.24.png)

a simple and general framework for image-to-image translation using conditional diffusion models. I2I translation four tasks (colorization, inpainting, uncropping, and JPEG decompression). task-specific hyper-parameter tuning, architecture customization, or any auxiliary loss, demonstrating a desirable degree of generality and flexibility ì—†ì´ strong GAN/regression baselines ë³´ë‹¤ ì¢‹ì€ ì„±ê³¼ë¥¼ ëƒˆë‹¤.

1. L2ì™€ L1 lossë¥¼ ë¹„êµë„ í•´ì¤Œ (in the denoising diffusion objective on sample diversity)
2. demonstrate the importance of self-attention through empirical architecture studies
3. advocate a unified evaluation protocol based on ImageNet

---

### Introduction

![|400](../source/Pasted%20image%2020231124211120.png)
Many such tasks, like those in FigureÂ [1](https://ar5iv.labs.arxiv.org/html/2111.05826#S0.F1), are complex inverse problems, where multiple output images are consistent with a single input.

A natural approach to image-to-image translation is to learn the conditional distribution of output images given the input using deep generative models that can capture multi-modal distributions in the high-dimensional space of images.

Nevertheless, GANs can be challenging to trainÂ (e.g.,Â Arjovsky etÂ al.,Â [2017](https://ar5iv.labs.arxiv.org/html/2111.05826#bib.bib3);Â Gulrajani etÂ al.,Â [2017](https://ar5iv.labs.arxiv.org/html/2111.05826#bib.bib25)), and often drop modes in the output distribution.

This paper investigates the general applicability ofÂ _Palette_, our implementation of image-to-image diffusion models, to a suite of four distinct and challenging tasks, namely colorization, inpainting, uncropping (_a.k.a_Â outpainting or extrapolation), and JPEG artifact removal.

With no task-specific architecture customization, and no changes to the hyper-parameters or the loss, Palettecan deliver high-fidelity outputs across all four tasks.

We find that while L2Â and L1 losses in the denoising objective yield similar sample-quality scores,Â L2Â leads to a higher degree of diversity in model samples, whereasÂ L1Â produces more conservative outputs.

We also find that removing self-attention layers from the U-Net architecture of Palette, in order to build a fully convolutional model, hurts performance.

**Contribution ì •ë¦¬**

1. Palette, implementation of I2I diffusion models
2. Recognize the impact of L1 vs L2 in the denoising objective on sample diversity
3. Show the importance of self-attention through empirical studies.
4. Propose a unified evalution protocol across image translation tasks based on the ImageNet dataset.

---

### Related works

**inpainting**

linear inverse tasks

**Image uncropping**

ë³´í†µ inpaintingë³´ë‹¤ ì–´ë ¤ìš´ taskë¡œ ì—¬ê²¨ì§„ë‹¤.

**Colorization**

scene understandingì„ ìš”êµ¬í•˜ëŠ” task!

**JPEG decompression**

nonlinear inverse problem for restoring realistic textures and removing compression artifacts.

---

### PALLETE

**architecture;**

The network architecture is based on the 256Ã—256 class-conditional U-Net model of [Dhariwal and Nichol 2021]. The two main differences between our architecture and theirs are (i) absence of class-conditioning, and (ii) additional conditioning of the source image via concatenation, following [Saharia et al. 2021].

**loss function;**
![](../source/ìŠ¤í¬ë¦°ìƒ·%202023-11-24%20ì˜¤í›„%209.11.34.png)

---

### The Role of Self-Attention in Diffusion Model Architectures

The results in Table 6 thus clearly show that models trained with the ğ¿2 loss have greater sample diversity than those trained with the ğ¿1 loss.