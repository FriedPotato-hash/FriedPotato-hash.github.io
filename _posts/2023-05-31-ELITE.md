
### Encoding Visual Concepts into Textual Embeddings for Customized Text-to-Image Generation

created at : 2023-05-31 21:15
#arxiv23_Feb #CLIPspace #learning-based #encoder

## Intro
- leaning-based encoder ì‚¬ìš©í•˜ì—¬ concept customizationì„ ì •í™•í•˜ê³  ë¹ ë¥´ê²Œ ì§„í–‰í•¨. ì´ëŠ” global, local mapping networkë¡œ êµ¬ì„±ëœë‹¤. local mapping networkëŠ” cross attn layerì— detailí•œ objectì˜ ì •ë³´ë¥¼ ë„£ì–´ì£¼ë©°, patch feature ë½‘ì•„ì„œ ë„£ìŒ.
![[Pasted image 20230531211758.png]]

## Method
- Image EncoderëŠ” CLIP image encoder (pretrained)ë¥¼ ì‚¬ìš©í•˜ê³  CLIP intermediate layerê°€ ê°ê° hierarchical featureë¥¼ ë½‘ì•„ë‚´ë¯€ë¡œ ê°€ì¥ ê¹Šì€ layerì—ì„œì˜ featureë¥¼ ì‚¬ìš©í•¨. ![[Pasted image 20230531212156.png]]
- ì‹¤ì œ ì‚¬ìš©ë˜ëŠ”ê±´ primary word í•˜ë‚˜ë¿. ë‹¤ë¥¸ word embeddingë“¤ì€ ê²°êµ­ auxillary informationë“¤ì„ ì—†ì• ì£¼ê¸° ìœ„í•´ ì¡´ì¬
- lossëŠ” ë‹¤ìŒê³¼ ê°™ì´ ì¤˜ì„œ global mapping ì„ í•™ìŠµì‹œí‚´.![[Pasted image 20230531212223.png]]
- inferenceëŠ” ë‹¤ìŒê³¼ ê°™ì´ í•´ì¤€ë‹¤. ![[Pasted image 20230531212609.png]]

## Experiment
- CLIP image encoderì—ì„œ layerì˜ ìœ„ì¹˜ì— ë”°ë¥¸ featureë¥¼ visualizationí•´ë³¸ ê²°ê³¼. deepest layerì—ì„œ ë½‘ì•„ë‚´ëŠ” ê²°ê³¼ê°€ ë³´í†µ generalí•œ conceptì„ ë‹´ê³  ìˆë‹¤.
- "A photo of a [w_i]"ë¼ëŠ” text promptë¡œ w_iëŠ” ith layerì˜ CLIP image encoderì˜ output embedding.![[Pasted image 20230531212302.png]]


## Conclusion from ğŸ¦–
- InstantBoothì—ê²Œ í° ì˜í–¥ì„ ì¤€ ë…¼ë¬¸ì¼ ë“¯.
- Image patch featureë¥¼ CLIP encoderë¥¼ í†µí•´ ë½‘ì•„ì„œ ì–˜ë¥¼ cross attnì— ë„£ì–´ì£¼ë©´ fine detailì„ ì¡ì•„ì£¼ê¸°ì— ë” ì¢‹ë‹¤ê³  í•˜ë„¤ìš”. 
- ìš°ë¦¬ taskì— ì‚¬ìš©í•˜ê¸° ìœ„í•´ì„œëŠ” UMM-Diffusion ë°©ì‹ê³¼ í˜¼í•©í•´ì„œ ì‚¬ìš©í•˜ë©´ ì¢‹ì„ë“¯.