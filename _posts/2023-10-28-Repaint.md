
---
title:  "Repaint: Inpainting using Denoising Diffusion Probabilistic Models"

categories:
  - Paper/inpainting

toc: true
toc_sticky: true
 
date: 2023-10-28 
last_modified_at: 2023-10-28

---
#cvpr22

## Intro
- Most existing approaches train for a certain distribution of masks, which limits their generalization capabilities to unseen mask types. Repaint inpaint the images with arbitrary mask shaped by using image prior of diffusion model (ddpm)
- Repaint condition the generation process by sampling from the given pixels during the reverse diffusion iterations. Remarkably, our model is therefore not trained for the inpainting task itself![](../source/Pasted%20image%2020231028003119.png)
## Method
- ‚ÄúThe process is conditioned on the masked input (left). It starts from a random Gaussian noise sample that is iteratively denoised until it produces a high-quality output. Since this process is stochastic, we can sample multiple diverse outputs. The DDPM prior forces a harmonized image, is able to reproduce texture from other regions, and inpaint semantically meaningful content.‚Äù
- ‚ÄúWe employ a pretrained unconditional DDPM as the generative prior. To condition the generation process, we only alter the reverse diffusion iterations by sampling the unmasked regions using the given image information. Since this technique does not modify or condition the original DDPM network itself, the model produces highquality and diverse output images for any inpainting form.‚Äù![](../source/Pasted%20image%2020231028003157.png)
- Apply noise only on the masked region![](../source/Pasted%20image%2020231028003206.png)
- **Algorithm of Repaint method**![](../source/Pasted%20image%2020231028003211.png)

## Experiment
- ![](../source/Pasted%20image%2020231028003217.png)![](../source/Pasted%20image%2020231028003220.png)![](../source/Pasted%20image%2020231028003224.png)![](../source/Pasted%20image%2020231028003230.png)

## Conclusion from ü¶ñ
- 