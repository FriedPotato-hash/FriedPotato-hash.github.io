![|300](../source/Pasted%20image%2020231208211758.png)

Cones 2 uses a simple yet effective representation to register a subject. The storage space required for each subject is approximately 5 KB. Moreover, Cones 2 allows for the flexible composition of various subjects without any model tuning.

### Existing Limitations

Existing algorithms suffer from high training cost and low success rate along with increased number of subjects.

Through learning a residual on top of the base embedding, we manage to robustly shift the raw subject to the customized subject given various text conditions.

By rectifying the activations in the cross-attention map, the layout appoints and separates the location of different subjects in the image, significantly alleviating the interference across them.

![](../source/Pasted%20image%2020231208211748.png)

(a) Given few-shot images of the customized subject, we fine-tune the text encoder to learn a residual embedding on top of the base embedding of raw subject. (b) Based on the residual embeddings, we then propose to employ layout as the spatial guidance for subject arrangement into the attention maps. After that, we could strengthen the signal of target subjects and weaken the signal of irrelevant subjects.

An ideal residual text embedding âˆ†custom that can robustly shift the raw category to a specific subject. The fine-tuned text encoder $E^{custom}$ is trained similarily with DreamBooth.

![|400](../source/Pasted%20image%2020231208211738.png)
![|400](../source/Pasted%20image%2020231208211732.png)
![|400](../source/Pasted%20image%2020231208211725.png)
![](../source/Pasted%20image%2020231208211719.png)
![](../source/Pasted%20image%2020231208211711.png))